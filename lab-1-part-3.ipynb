{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cifar/cifar-100-python/train', 'rb') as f:\n",
    "    data_train = pickle.load(f, encoding='latin1')\n",
    "with open('cifar/cifar-100-python/test', 'rb') as f:\n",
    "    data_test = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Здесь указать ваши классы по варианту!!!\n",
    "# 1. Номер группы + 15\n",
    "# 2. Номер варианта + 56\n",
    "# 3. ИУ5 (Номер варианта + 21); ГУИМЦ (80); Иностранцы (90)\n",
    "# (39 — клавиатуры, 58 — небо, 23 — внедорожники)\n",
    "CLASSES = [39, 58, 23]\n",
    "\n",
    "# массив\n",
    "train_X = data_train['data'].reshape(-1, 3, 32, 32)\n",
    "train_X = np.transpose(train_X, [0, 2, 3, 1]) # NCHW -> NHWC\n",
    "train_y = np.array(data_train['fine_labels'])\n",
    "mask = np.isin(train_y, CLASSES) # фильтруем данные, выбираем только те, которые относятся к нашим классам\n",
    "\n",
    "train_X = train_X[mask].copy()\n",
    "train_y = train_y[mask].copy()\n",
    "train_y = np.unique(train_y, return_inverse=1)[1]\n",
    "del data_train\n",
    "\n",
    "test_X = data_test['data'].reshape(-1, 3, 32, 32)\n",
    "test_X = np.transpose(test_X, [0, 2, 3, 1])\n",
    "test_y = np.array(data_test['fine_labels'])\n",
    "mask = np.isin(test_y, CLASSES)\n",
    "\n",
    "test_X = test_X[mask].copy()\n",
    "test_y = test_y[mask].copy()\n",
    "test_y = np.unique(test_y, return_inverse=1)[1]\n",
    "del data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input / 255.0\n",
    "        x = x - self.mean\n",
    "        x = x / self.std\n",
    "        return torch.flatten(x, start_dim=1) # nhwc -> nm\n",
    "\n",
    "class Cifar100_MLP(nn.Module):\n",
    "    def __init__(self, _seq : nn.Sequential):\n",
    "        super(Cifar100_MLP, self).__init__()\n",
    "        # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
    "        self.norm = Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025])\n",
    "        self.seq = _seq\n",
    "        #self.seq = nn.Sequential(\n",
    "        #    nn.Linear(32*32*3, hidden_size),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Linear(hidden_size, classes),\n",
    "        #)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.norm(input)\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_3(_batch_size, _epochs, _classes: int, _learning_rate:float, seq: nn.Sequential):\n",
    "  batch_size = _batch_size\n",
    "  dataloader = {}\n",
    "\n",
    "  for (X, y), part in zip([(train_X, train_y), (test_X, test_y)], ['train', 'test']):\n",
    "      tensor_x = torch.Tensor(X)\n",
    "      tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64), num_classes=_classes)/1.\n",
    "      dataset = TensorDataset(tensor_x, tensor_y)\n",
    "      dataloader[part] = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  model = Cifar100_MLP(seq)\n",
    "\n",
    "  print(model)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=_learning_rate)\n",
    "\n",
    "  EPOCHS = _epochs\n",
    "  # train data set\n",
    "  steps_per_epoch_train = len(dataloader['train'])\n",
    "  # test data set (валидация)\n",
    "  steps_per_epoch_test = len(dataloader['test'])\n",
    "\n",
    "  losses_train_x = []\n",
    "  losses_train_y = []\n",
    "  losses_test_x = []\n",
    "  losses_test_y = []\n",
    "\n",
    "  for epoch in range(EPOCHS):  # проход по набору данных несколько раз\n",
    "      running_loss = 0.0\n",
    "      model.train()\n",
    "\n",
    "      for i, batch in enumerate(dataloader['train'], 0):\n",
    "          # получение одного минибатча; batch это двуэлементный список из [inputs, labels]\n",
    "          inputs, labels = batch\n",
    "\n",
    "          # очищение прошлых градиентов с прошлой итерации\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # прямой + обратный проходы + оптимизация\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          \n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          # для подсчёта статистик\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      # график\n",
    "      losses_train_x.append(epoch)\n",
    "      losses_train_y.append(running_loss / steps_per_epoch_train)\n",
    "\n",
    "      running_loss = 0.0\n",
    "      model.eval() # модель переводится в evaluation mode (режим оценки)\n",
    "      with torch.no_grad(): # отключение автоматического дифференцирования\n",
    "          for i, batch in enumerate(dataloader['test'], 0):\n",
    "              inputs, labels = batch\n",
    "\n",
    "              outputs = model(inputs)\n",
    "              loss = criterion(outputs, labels)\n",
    "              running_loss += loss.item()\n",
    "\n",
    "      # график\n",
    "      losses_test_x.append(epoch)\n",
    "      losses_test_y.append(running_loss / steps_per_epoch_test)\n",
    "\n",
    "  print('Обучение закончено')\n",
    "  \n",
    "  min_losses_test_y = max(losses_test_y)\n",
    "  min_losses_test_x = 0\n",
    "  for i in range(0, len(losses_test_y)):\n",
    "      if losses_test_y[i] < min_losses_test_y:\n",
    "          min_losses_test_y = losses_test_y[i]\n",
    "          min_losses_test_x = i\n",
    "  \n",
    "  print(\"Переобучение произошло на эпохе: \", min_losses_test_x)\n",
    "  print(\"Ошибка в момент переобучения: \", min_losses_test_y)\n",
    "\n",
    "  for part in ['train', 'test']:\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad(): # отключение автоматического дифференцирования\n",
    "        for i, data in enumerate(dataloader[part], 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            outputs = model(inputs).detach().numpy()\n",
    "            y_pred.append(outputs)\n",
    "            y_true.append(labels.numpy())\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        print(part)\n",
    "        print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1), digits=4, target_names=list(map(str, CLASSES))))\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "HIDDEN_SIZE = 32\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_OF_CLASSES = 3\n",
    "EPOCHS = 250\n",
    "def default_sequention():\n",
    "    return nn.Sequential(\n",
    "            # полносвязный слой (входной - скрытый)\n",
    "            nn.Linear(32*32*3, HIDDEN_SIZE),\n",
    "            # функция активации для нейронов скрытого слоя\n",
    "            nn.ReLU(),\n",
    "            # полносвязный слой (скрытый - выходной)\n",
    "            nn.Linear(HIDDEN_SIZE, NUM_OF_CLASSES),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  91\n",
      "Ошибка в моменте переобучения:  0.5351938704649607\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9920    0.9900    0.9910       500\n",
      "          58     0.9920    0.9920    0.9920       500\n",
      "          23     0.9980    1.0000    0.9990       500\n",
      "\n",
      "    accuracy                         0.9940      1500\n",
      "   macro avg     0.9940    0.9940    0.9940      1500\n",
      "weighted avg     0.9940    0.9940    0.9940      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6967    0.8500    0.7658       100\n",
      "          58     0.7442    0.6400    0.6882       100\n",
      "          23     0.8696    0.8000    0.8333       100\n",
      "\n",
      "    accuracy                         0.7633       300\n",
      "   macro avg     0.7702    0.7633    0.7624       300\n",
      "weighted avg     0.7702    0.7633    0.7624       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task_3(BATCH_SIZE, EPOCHS, NUM_OF_CLASSES, LEARNING_RATE, default_sequention())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
