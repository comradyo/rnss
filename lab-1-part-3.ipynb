{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cifar/cifar-100-python/train', 'rb') as f:\n",
    "    data_train = pickle.load(f, encoding='latin1')\n",
    "with open('cifar/cifar-100-python/test', 'rb') as f:\n",
    "    data_test = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Здесь указать ваши классы по варианту!!!\n",
    "# 1. Номер группы + 15\n",
    "# 2. Номер варианта + 56\n",
    "# 3. ИУ5 (Номер варианта + 21); ГУИМЦ (80); Иностранцы (90)\n",
    "# (39 — клавиатуры, 58 — небо, 23 — внедорожники)\n",
    "CLASSES = [39, 58, 23]\n",
    "\n",
    "# массив\n",
    "train_X = data_train['data'].reshape(-1, 3, 32, 32)\n",
    "train_X = np.transpose(train_X, [0, 2, 3, 1]) # NCHW -> NHWC\n",
    "train_y = np.array(data_train['fine_labels'])\n",
    "mask = np.isin(train_y, CLASSES) # фильтруем данные, выбираем только те, которые относятся к нашим классам\n",
    "\n",
    "train_X = train_X[mask].copy()\n",
    "train_y = train_y[mask].copy()\n",
    "train_y = np.unique(train_y, return_inverse=1)[1]\n",
    "del data_train\n",
    "\n",
    "test_X = data_test['data'].reshape(-1, 3, 32, 32)\n",
    "test_X = np.transpose(test_X, [0, 2, 3, 1])\n",
    "test_y = np.array(data_test['fine_labels'])\n",
    "mask = np.isin(test_y, CLASSES)\n",
    "\n",
    "test_X = test_X[mask].copy()\n",
    "test_y = test_y[mask].copy()\n",
    "test_y = np.unique(test_y, return_inverse=1)[1]\n",
    "del data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input / 255.0\n",
    "        x = x - self.mean\n",
    "        x = x / self.std\n",
    "        return torch.flatten(x, start_dim=1) # nhwc -> nm\n",
    "\n",
    "class Cifar100_MLP(nn.Module):\n",
    "    def __init__(self, _seq : nn.Sequential):\n",
    "        super(Cifar100_MLP, self).__init__()\n",
    "        # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1\n",
    "        self.norm = Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025])\n",
    "        self.seq = _seq\n",
    "        #self.seq = nn.Sequential(\n",
    "        #    nn.Linear(32*32*3, hidden_size),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Linear(hidden_size, classes),\n",
    "        #)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.norm(input)\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_3(_batch_size, _epochs, _classes: int, _learning_rate:float, seq: nn.Sequential):\n",
    "  batch_size = _batch_size\n",
    "  dataloader = {}\n",
    "\n",
    "  for (X, y), part in zip([(train_X, train_y), (test_X, test_y)], ['train', 'test']):\n",
    "      tensor_x = torch.Tensor(X)\n",
    "      tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64), num_classes=_classes)/1.\n",
    "      dataset = TensorDataset(tensor_x, tensor_y)\n",
    "      dataloader[part] = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  model = Cifar100_MLP(seq)\n",
    "\n",
    "  print(model)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=_learning_rate)\n",
    "\n",
    "  EPOCHS = _epochs\n",
    "  # train data set\n",
    "  steps_per_epoch_train = len(dataloader['train'])\n",
    "  # test data set (валидация)\n",
    "  steps_per_epoch_test = len(dataloader['test'])\n",
    "\n",
    "  losses_train_x = []\n",
    "  losses_train_y = []\n",
    "  losses_test_x = []\n",
    "  losses_test_y = []\n",
    "\n",
    "  for epoch in range(EPOCHS):  # проход по набору данных несколько раз\n",
    "      running_loss = 0.0\n",
    "      model.train()\n",
    "\n",
    "      for i, batch in enumerate(dataloader['train'], 0):\n",
    "          # получение одного минибатча; batch это двуэлементный список из [inputs, labels]\n",
    "          inputs, labels = batch\n",
    "\n",
    "          # очищение прошлых градиентов с прошлой итерации\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # прямой + обратный проходы + оптимизация\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          \n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          # для подсчёта статистик\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      # график\n",
    "      losses_train_x.append(epoch)\n",
    "      losses_train_y.append(running_loss / steps_per_epoch_train)\n",
    "\n",
    "      running_loss = 0.0\n",
    "      model.eval() # модель переводится в evaluation mode (режим оценки)\n",
    "      with torch.no_grad(): # отключение автоматического дифференцирования\n",
    "          for i, batch in enumerate(dataloader['test'], 0):\n",
    "              inputs, labels = batch\n",
    "\n",
    "              outputs = model(inputs)\n",
    "              loss = criterion(outputs, labels)\n",
    "              running_loss += loss.item()\n",
    "\n",
    "      # график\n",
    "      losses_test_x.append(epoch)\n",
    "      losses_test_y.append(running_loss / steps_per_epoch_test)\n",
    "\n",
    "  print('Обучение закончено')\n",
    "  \n",
    "  min_losses_test_y = max(losses_test_y)\n",
    "  min_losses_test_x = 0\n",
    "  for i in range(0, len(losses_test_y)):\n",
    "      if losses_test_y[i] < min_losses_test_y:\n",
    "          min_losses_test_y = losses_test_y[i]\n",
    "          min_losses_test_x = i\n",
    "  \n",
    "  print(\"Переобучение произошло на эпохе: \", min_losses_test_x)\n",
    "  print(\"Ошибка в момент переобучения: \", min_losses_test_y)\n",
    "\n",
    "  for part in ['train', 'test']:\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad(): # отключение автоматического дифференцирования\n",
    "        for i, data in enumerate(dataloader[part], 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            outputs = model(inputs).detach().numpy()\n",
    "            y_pred.append(outputs)\n",
    "            y_true.append(labels.numpy())\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        print(part)\n",
    "        print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1), digits=4, target_names=list(map(str, CLASSES))))\n",
    "        print('-'*50)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "HIDDEN_SIZE = 32\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_OF_CLASSES = 3\n",
    "EPOCHS = 250\n",
    "def default_sequention():\n",
    "    return nn.Sequential(\n",
    "            # полносвязный слой (входной - скрытый)\n",
    "            nn.Linear(32*32*3, HIDDEN_SIZE),\n",
    "            # функция активации для нейронов скрытого слоя\n",
    "            nn.ReLU(),\n",
    "            # полносвязный слой (скрытый - выходной)\n",
    "            nn.Linear(HIDDEN_SIZE, NUM_OF_CLASSES),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  91\n",
      "Ошибка в моменте переобучения:  0.5351938704649607\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9920    0.9900    0.9910       500\n",
      "          58     0.9920    0.9920    0.9920       500\n",
      "          23     0.9980    1.0000    0.9990       500\n",
      "\n",
      "    accuracy                         0.9940      1500\n",
      "   macro avg     0.9940    0.9940    0.9940      1500\n",
      "weighted avg     0.9940    0.9940    0.9940      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6967    0.8500    0.7658       100\n",
      "          58     0.7442    0.6400    0.6882       100\n",
      "          23     0.8696    0.8000    0.8333       100\n",
      "\n",
      "    accuracy                         0.7633       300\n",
      "   macro avg     0.7702    0.7633    0.7624       300\n",
      "weighted avg     0.7702    0.7633    0.7624       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task_3(BATCH_SIZE, EPOCHS, NUM_OF_CLASSES, LEARNING_RATE, default_sequention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  72\n",
      "Ошибка в моменте переобучения:  0.5693243046601614\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9010    0.9280    0.9143       500\n",
      "          58     0.9367    0.8880    0.9117       500\n",
      "          23     0.9511    0.9720    0.9614       500\n",
      "\n",
      "    accuracy                         0.9293      1500\n",
      "   macro avg     0.9296    0.9293    0.9291      1500\n",
      "weighted avg     0.9296    0.9293    0.9291      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6783    0.7800    0.7256       100\n",
      "          58     0.6905    0.5800    0.6304       100\n",
      "          23     0.8416    0.8500    0.8458       100\n",
      "\n",
      "    accuracy                         0.7367       300\n",
      "   macro avg     0.7368    0.7367    0.7339       300\n",
      "weighted avg     0.7368    0.7367    0.7339       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task_3(BATCH_SIZE, 75, NUM_OF_CLASSES, LEARNING_RATE, default_sequention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  314\n",
      "Ошибка в моменте переобучения:  0.5744607051213583\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9202    0.9220    0.9211       500\n",
      "          58     0.9249    0.9120    0.9184       500\n",
      "          23     0.9526    0.9640    0.9583       500\n",
      "\n",
      "    accuracy                         0.9327      1500\n",
      "   macro avg     0.9326    0.9327    0.9326      1500\n",
      "weighted avg     0.9326    0.9327    0.9326      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6639    0.8100    0.7297       100\n",
      "          58     0.6923    0.5400    0.6067       100\n",
      "          23     0.8200    0.8200    0.8200       100\n",
      "\n",
      "    accuracy                         0.7233       300\n",
      "   macro avg     0.7254    0.7233    0.7188       300\n",
      "weighted avg     0.7254    0.7233    0.7188       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Уменьшили learning rate для повышения точности. Соответственно увеличили количество эпох\n",
    "task_3(BATCH_SIZE, 375, NUM_OF_CLASSES, 0.001, default_sequention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  262\n",
      "Ошибка в момент переобучения:  0.5599540869394938\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.8706    0.8880    0.8792       500\n",
      "          58     0.8921    0.8600    0.8758       500\n",
      "          23     0.9429    0.9580    0.9504       500\n",
      "\n",
      "    accuracy                         0.9020      1500\n",
      "   macro avg     0.9019    0.9020    0.9018      1500\n",
      "weighted avg     0.9019    0.9020    0.9018      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.7043    0.8100    0.7535       100\n",
      "          58     0.7000    0.6300    0.6632       100\n",
      "          23     0.8632    0.8200    0.8410       100\n",
      "\n",
      "    accuracy                         0.7533       300\n",
      "   macro avg     0.7558    0.7533    0.7526       300\n",
      "weighted avg     0.7558    0.7533    0.7526       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Обнаружено переобучение для прошлой итерации. Снизили количество эпох до 314.\n",
    "result = task_3(BATCH_SIZE, 314, NUM_OF_CLASSES, 0.001, default_sequention())\n",
    "# ВТОРОЙ СПОСОБ: сохранение всей архитектуры\n",
    "PATH2 = 'cifar_cnn.pt'\n",
    "torch.save(result, PATH2)\n",
    "# загрузка\n",
    "new_model_2 = torch.load(PATH2)\n",
    "new_model_2.eval()\n",
    "\n",
    "# входной тензор для модели\n",
    "x = torch.randn(1, 32, 32, 3, requires_grad=True).to(\"cpu\")\n",
    "torch_out = result(x)\n",
    "\n",
    "# экспорт модели\n",
    "torch.onnx.export(result,               # модель\n",
    "                  x,                   # входной тензор (или кортеж нескольких тензоров)\n",
    "                  \"cifar100_CNN_lr_1.onnx\", # куда сохранить (либо путь к файлу либо fileObject)\n",
    "                  export_params=True,  # сохраняет веса обученных параметров внутри файла модели\n",
    "                  opset_version=9,     # версия ONNX\n",
    "                  do_constant_folding=True,  # следует ли выполнять укорачивание констант для оптимизации\n",
    "                  input_names = ['input'],   # имя входного слоя\n",
    "                  output_names = ['output'],  # имя выходного слоя\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # динамичные оси, в данном случае только размер пакета\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  417\n",
      "Ошибка в моменте переобучения:  0.5591932982206345\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9162    0.8960    0.9060       500\n",
      "          58     0.9016    0.8980    0.8998       500\n",
      "          23     0.9337    0.9580    0.9457       500\n",
      "\n",
      "    accuracy                         0.9173      1500\n",
      "   macro avg     0.9172    0.9173    0.9172      1500\n",
      "weighted avg     0.9172    0.9173    0.9172      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.7321    0.8200    0.7736       100\n",
      "          58     0.7204    0.6700    0.6943       100\n",
      "          23     0.8842    0.8400    0.8615       100\n",
      "\n",
      "    accuracy                         0.7767       300\n",
      "   macro avg     0.7789    0.7767    0.7765       300\n",
      "weighted avg     0.7789    0.7767    0.7765       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Увеличение batch size в 1.5 раз \n",
    "task_3(192, 471, NUM_OF_CLASSES, 0.001, default_sequention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  368\n",
      "Ошибка в моменте переобучения:  0.5625549107789993\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.8860    0.8860    0.8860       500\n",
      "          58     0.8952    0.8880    0.8916       500\n",
      "          23     0.9405    0.9480    0.9442       500\n",
      "\n",
      "    accuracy                         0.9073      1500\n",
      "   macro avg     0.9072    0.9073    0.9073      1500\n",
      "weighted avg     0.9072    0.9073    0.9073      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.7143    0.8000    0.7547       100\n",
      "          58     0.7356    0.6400    0.6845       100\n",
      "          23     0.8416    0.8500    0.8458       100\n",
      "\n",
      "    accuracy                         0.7633       300\n",
      "   macro avg     0.7638    0.7633    0.7617       300\n",
      "weighted avg     0.7638    0.7633    0.7617       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Обнаружено переобучение для прошлой итерации. \n",
    "task_3(192, 417, NUM_OF_CLASSES, 0.001, default_sequention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  46\n",
      "Ошибка в моменте переобучения:  0.6377203365166982\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9755    0.9540    0.9646       500\n",
      "          58     0.9683    0.9780    0.9731       500\n",
      "          23     0.9822    0.9940    0.9881       500\n",
      "\n",
      "    accuracy                         0.9753      1500\n",
      "   macro avg     0.9753    0.9753    0.9753      1500\n",
      "weighted avg     0.9753    0.9753    0.9753      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6780    0.8000    0.7339       100\n",
      "          58     0.6951    0.5700    0.6264       100\n",
      "          23     0.8200    0.8200    0.8200       100\n",
      "\n",
      "    accuracy                         0.7300       300\n",
      "   macro avg     0.7310    0.7300    0.7268       300\n",
      "weighted avg     0.7310    0.7300    0.7268       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Создали новую модель FC(8), FC(3). \n",
    "seq = nn.Sequential(\n",
    "            # полносвязный слой (входной - скрытый)\n",
    "            nn.Linear(32*32*3, 8),\n",
    "            # функция активации для нейронов скрытого слоя\n",
    "            nn.ReLU(),\n",
    "            # полносвязный слой (скрытый - выходной)\n",
    "            nn.Linear(8, NUM_OF_CLASSES),\n",
    "        )\n",
    "task_3(BATCH_SIZE, EPOCHS, NUM_OF_CLASSES, LEARNING_RATE, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  240\n",
      "Ошибка в моменте переобучения:  0.6285305817921957\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.8305    0.8820    0.8555       500\n",
      "          58     0.8588    0.7540    0.8030       500\n",
      "          23     0.8717    0.9240    0.8971       500\n",
      "\n",
      "    accuracy                         0.8533      1500\n",
      "   macro avg     0.8537    0.8533    0.8518      1500\n",
      "weighted avg     0.8537    0.8533    0.8518      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6842    0.7800    0.7290       100\n",
      "          58     0.6988    0.5800    0.6339       100\n",
      "          23     0.8350    0.8600    0.8473       100\n",
      "\n",
      "    accuracy                         0.7400       300\n",
      "   macro avg     0.7393    0.7400    0.7367       300\n",
      "weighted avg     0.7393    0.7400    0.7367       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Приведение к оптимальным гиперпараметрам.\n",
    "seq = nn.Sequential(\n",
    "            # полносвязный слой (входной - скрытый)\n",
    "            nn.Linear(32*32*3, 8),\n",
    "            # функция активации для нейронов скрытого слоя\n",
    "            nn.ReLU(),\n",
    "            # полносвязный слой (скрытый - выходной)\n",
    "            nn.Linear(8, NUM_OF_CLASSES),\n",
    "        )\n",
    "task_3(BATCH_SIZE, 52 * 5, NUM_OF_CLASSES, 0.001, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  99\n",
      "Ошибка в моменте переобучения:  0.6560724973678589\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.9793    0.9440    0.9613       500\n",
      "          58     0.9392    0.9880    0.9630       500\n",
      "          23     0.9919    0.9760    0.9839       500\n",
      "\n",
      "    accuracy                         0.9693      1500\n",
      "   macro avg     0.9701    0.9693    0.9694      1500\n",
      "weighted avg     0.9701    0.9693    0.9694      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6726    0.7600    0.7136       100\n",
      "          58     0.6264    0.5700    0.5969       100\n",
      "          23     0.7917    0.7600    0.7755       100\n",
      "\n",
      "    accuracy                         0.6967       300\n",
      "   macro avg     0.6969    0.6967    0.6953       300\n",
      "weighted avg     0.6969    0.6967    0.6953       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Создали новую модель FC(8), FC(8) FC(3). \n",
    "seq = nn.Sequential(\n",
    "            nn.Linear(32*32*3, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            # полносвязный слой (скрытый - выходной)\n",
    "            nn.Linear(8, NUM_OF_CLASSES),\n",
    "        )\n",
    "task_3(BATCH_SIZE, EPOCHS, NUM_OF_CLASSES, LEARNING_RATE, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar100_MLP(\n",
      "  (norm): Normalize()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Обучение закончено\n",
      "Переобучение произошло на эпохе:  346\n",
      "Ошибка в моменте переобучения:  0.6534637014071146\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.7449    0.8700    0.8026       500\n",
      "          58     0.7964    0.6180    0.6959       500\n",
      "          23     0.8447    0.8920    0.8677       500\n",
      "\n",
      "    accuracy                         0.7933      1500\n",
      "   macro avg     0.7953    0.7933    0.7887      1500\n",
      "weighted avg     0.7953    0.7933    0.7887      1500\n",
      "\n",
      "--------------------------------------------------\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39     0.6311    0.7700    0.6937       100\n",
      "          58     0.6316    0.4800    0.5455       100\n",
      "          23     0.7745    0.7900    0.7822       100\n",
      "\n",
      "    accuracy                         0.6800       300\n",
      "   macro avg     0.6791    0.6800    0.6738       300\n",
      "weighted avg     0.6791    0.6800    0.6738       300\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Приведение к оптимальным гиперпараметрам.\n",
    "seq = nn.Sequential(\n",
    "            nn.Linear(32*32*3, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            # полносвязный слой (скрытый - выходной)\n",
    "            nn.Linear(8, NUM_OF_CLASSES),\n",
    "        )\n",
    "task_3(BATCH_SIZE, 350, NUM_OF_CLASSES, 0.001, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3(BATCH_SIZE, EPOCHS, NUM_OF_CLASSES, LEARNING_RATE, default_sequention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
